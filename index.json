[{"content":"在 docker compose 上部署 Home Assistant 确保已安装 docker 👉：docker 和 docker-compose 安装、配置、卸载（windows+linux）-CSDN博客\n参考文档： Linux - Home Assistant\n创建目录 home_assistant，在目录中新建 docker-compose.yml，内容如下：\nservices: homeassistant: container_name: homeassistant image: \u0026#34;ghcr.io/home-assistant/home-assistant:stable\u0026#34; volumes: # 如果在 Windows 目录下，建议改为相对路径， 如 ./PATH_TO_YOUR_CONFIG:/config - /PATH_TO_YOUR_CONFIG:/config - /etc/localtime:/etc/localtime:ro - /run/dbus:/run/dbus:ro restart: unless-stopped privileged: true network_mode: host 在目录下通过命令启动 docker-compose：\ndocker compose up -d 在 Home Assistant 集成 MQTT Home Assistant 在 MQTT 中相当于一个特殊的设备，它实际上监控着其他的 IoT 设备。\n关于 MQTT 的一些概念：MQTT 核心概念 | EMQX文档\nHA 通过订阅一些特定主题（假如是 /online）的信息来获取其他设备的状态，而这些信息当然是由其他 IoT 设备发布的。用户可以设定一个 /open 主题，然后通过 HA 发布一个该主题的信息来启动某些设备。\n推荐阅读： 智能家居之旅，第二站：设备接入HomeAssistant的方法 » 智能家居技术论坛\n文档（不推荐）：MQTT - Home Assistant \u0026mdash; MQTT - Home Assistant\n","permalink":"https://yusjade.github.io/posts/valid_homeassistant_use_mqtt/","summary":"\u003ch2 id=\"在-docker-compose-上部署-home-assistant\"\u003e在 docker compose 上部署 Home Assistant\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e确保已安装 docker 👉：\u003ca href=\"https://blog.csdn.net/ziqibit/article/details/129698618\"\u003edocker 和 docker-compose 安装、配置、卸载（windows+linux）-CSDN博客\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e参考文档： \u003ca href=\"https://www.home-assistant.io/installation/linux#docker-compose\"\u003eLinux - Home Assistant\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e创建目录 home_assistant，在目录中新建 docker-compose.yml，内容如下：\u003c/p\u003e","title":"想法验证 二 | Home Assistant 集成 MQTT"},{"content":" 目标：esp8266 接受来自 mqtt 消息队列的信息并完成指定动作（电灯、驱动舵机等\u0026hellip;）\nMQTT 是一种轻量级的发布/订阅消息传输协议，专为低带宽、不稳定网络环境下的物联网设备通信而设计。、\n了解 MQTT：MQTT 核心概念 | EMQX文档\nESP8266 是一款低成本、高性能的 Wi-Fi 芯片，集成了 TCP/IP 协议栈，广泛应用于物联网设备中，能够实现无线网络连接和数据传输。\n主要参考博客：使用ESP8266连接MQTT服务器！快速学习ESP8266各功能！万字长文内含示例代码（下）_esp8266 mqtt-CSDN博客\n技术选型和硬件选择🛠️ mqtt 消息队列：EMQX （使用docker自部署） mqtt 客户端：MQTTX esp8266: ESP-01S安可信 开发平台：Arduino 依赖库：PubSubClient 安装 EMQX 和 客户端 MQTTX 使用 docker 快速部署 EMQX：\n确保已安装 docker 👉：docker 和 docker-compose 安装、配置、卸载（windows+linux）-CSDN博客\n参考 emqx/README-CN.md at master · emqx/emqx，在终端使用下列命令启动 emqx ：\ndocker run -d --name emqx \\ -p 1883:1883 \\ -p 8083:8083 \\ -p 8084:8084 \\ -p 8883:8883 \\ -p 18083:18083 \\ emqx/emqx:latest MQTTX 下载地址：MQTTX：全功能 MQTT 客户端工具\n使用教程参考： 开始使用 - MQTTX 文档\n配置 Arduino ESP8266 开发环境 安装 Arduino IDE 以及 ESP8266 的核心库 esp8266/Arduino: ESP8266 core for Arduino\n安装教程在上面的仓库中，这里摘一下：\n通过 Boards Manager 安装 从 1.6.4 版本开始，Arduino 允许使用 Boards Manager 安装第三方平台包。我们提供了适用于 Windows、Mac OS 和 Linux（32 位和 64 位）的包。\n下载并安装 Arduino IDE 2.x 启动 Arduino 并打开 Preferences 窗口 在 Arduino IDE 的 文件 \u0026gt; 首选项 \u0026gt; 其他开发板管理地址 字段中输入 https://arduino.esp8266.com/stable/package_esp8266com_index.json ，您可以添加多个 URL，用逗号分隔它们。 从 工具 \u0026gt; 开发板 菜单中打开开发板管理器并安装 esp8266 平台（安装后别忘了从“工具”\u0026gt;“开发板”菜单中选择您的 ESP8266 开发板）。 安装 ESP8266 的 MQTT 库 PubSubClient - Arduino Reference\n下载最新版本，在 Arduino IDE 的项目-导入库-添加.ZIP库..，选择刚刚下载好的 .zip 压缩包即可安装完成。\n连接 MQTT 的代码可参考：使用ESP8266连接MQTT服务器！_esp8266 mqtt-CSDN博客\n","permalink":"https://yusjade.github.io/posts/valid_esp8266_use_mqtt/","summary":"\u003cblockquote\u003e\n\u003cp\u003e目标：esp8266 接受来自 mqtt 消息队列的信息并完成指定动作（电灯、驱动舵机等\u0026hellip;）\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eMQTT 是一种轻量级的发布/订阅消息传输协议，专为低带宽、不稳定网络环境下的物联网设备通信而设计。、\u003c/p\u003e","title":"想法验证 一 | 在 esp8266 使用 MQTT 通信"},{"content":"资料索引：\n原理图与 PCB 设计：赛博魔杖_STM32卷积神经网络 | PCB_Main | 嘉立创EDA(专业版) - V2.2.36 源代码仓库：🐈‍⬛lyg09270/Cyberry_Potter_Electromagic_Wand: 一根可以通过在空中画出不同的形状来控制的魔杖(像真正的巫师一样). 模块功能总结 硬件和代码主要实现了以下功能：\n获取按键的按下、长按、松开状态 通过按键状态控制对传感器的读取行为 获取按键的按下、长按、松开状态 按键被按下时触发了外部中断，在中断处理中记录当前按键开关状态和上一次开关状态（按下或松开），累加状态计数器，进而判断按键状态。\nSTM32F103CBT6 引脚定义 原理图如下， user_button 模块连接 PA0-WKUP 引脚。当触发沿从引脚输入时触发中断，由程序获取按键状态。\nWKUP: 唤醒功能，与本文关系应该不大。\nPA0, P 即 PIN （引脚）、A 即 （GIOP 的 A 组引脚）、0 即组内的第零号。\n按键原理图 原作者使用了 TS24CA 和 ZX-QC34-2TPD 两种轻触开关，但是电路设计上有所不同， reset_button 和 boot0_button 分别使用了上拉电阻和下拉电阻，而 user_button 并没有\u0026hellip;\n由于打算使用 HH-D02 芯片和独立的 MPU-6050 模块，所以可能还需自行设计控制器来开启动作识别的功能，不过也能在软件逻辑上规避一下这个问题~\n代码部分：中断与定时器消抖 待续\u0026hellip;\n通过按键状态控制对传感器的读取行为 这部分在主循环中进行\u0026hellip;\n","permalink":"https://yusjade.github.io/posts/cyberry_potter_user_button/","summary":"\u003cp\u003e\u003cem\u003e资料索引：\u003c/em\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e原理图与 PCB 设计：\u003ca href=\"https://pro.lceda.cn/editor#id=ac55f5c253d44bad946b1e8647b2ef23,tab=*d46dc1c7cffa4e33863edc31fd66bab8@ac55f5c253d44bad946b1e8647b2ef23%7C6bf1eb7b2f094edea220c124a1d5fb3b@ac55f5c253d44bad946b1e8647b2ef23\"\u003e赛博魔杖_STM32卷积神经网络 | PCB_Main | 嘉立创EDA(专业版) - V2.2.36\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e源代码仓库：🐈‍⬛\u003ca href=\"https://github.com/lyg09270/Cyberry_Potter_Electromagic_Wand\"\u003elyg09270/Cyberry_Potter_Electromagic_Wand: 一根可以通过在空中画出不同的形状来控制的魔杖(像真正的巫师一样).\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"模块功能总结\"\u003e模块功能总结\u003c/h2\u003e\n\u003cp\u003e硬件和代码主要实现了以下功能：\u003c/p\u003e","title":"赛博魔杖 | user_button 模块分析"},{"content":" 最近又用回了 Windows 开发环境，cd 时不习惯 Win 的目录结构，于是发现了一个能自定义指令的方法。\n在 $profile 文件中定义函数 在终端执行下列命令，会打印出所有配置文件的位置，形如 X:\\...\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1。 配置文件通常只有一个，直接编辑这个文件即可。\n# 查看终端配置文件的位置 $profile 下面定义一个函数，用于 cd 到我的 CodeField 文件夹：\nfunction TP-codefield { Set-Location E:\\Documents\\CodeField\\ } 这样就能在终端直接通过 TP-codefield 函数直接跳转到 CodeField。\n","permalink":"https://yusjade.github.io/posts/pwsh_write_a_function_in_profile/","summary":"\u003cblockquote\u003e\n\u003cp\u003e最近又用回了 Windows 开发环境，cd 时不习惯 Win 的目录结构，于是发现了一个能\u003cstrong\u003e自定义指令\u003c/strong\u003e的方法。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"在-profile-文件中定义函数\"\u003e在 $profile 文件中定义函数\u003c/h2\u003e\n\u003cp\u003e在终端执行下列命令，会打印出所有配置文件的位置，形如 \u003ccode\u003eX:\\...\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1\u003c/code\u003e。\n配置文件通常只有一个，直接编辑这个文件即可。\u003c/p\u003e","title":"Pwsh | Tips: 如何快速 cd 到常用目录"},{"content":"解决办法 在启用 CMAKE_AUTOUIC 的同时，将使用了#include \u0026quot;ui_\u0026lt;base_ui\u0026gt;.h\u0026quot;的头文件加入到add_executable的 SOURCE 中即可。\n参考 CMake 文档：CMake Doc | AUTOUIC¶\n猜测原因 如果未将包含了#include \u0026quot;ui_\u0026lt;base_ui\u0026gt;.h\u0026quot;的头文件加入到add_executable的 SOURCE 中，那么执行编译时会抛出找不到 \u0026ldquo;ui_\u0026lt;base_ui\u0026gt;.h\u0026rdquo; 头文件的错误，从输出中可以发现，其实 UIC 的编译任务在这之前已经完成了，说明 CMake 并没有发现需要编译的 .ui 文件。\nCMake 文档如此描述，构建时 CMake 会扫描源文件，若发现有头文件或源文件包含了 \u0026quot;ui_\u0026lt;base_ui\u0026gt;.h\u0026quot; 形式的头文件，则会搜索工程中 \u0026quot;\u0026lt;base_ui\u0026gt;.ui\u0026quot; 并调用 QT 提供的 uic 工具，将其编译为对应的头文件。\n% cmake --build ./build [ 20%] Automatic MOC and UIC for target test_autouic [ 20%] Built target test_autouic_autogen [ 40%] Building CXX object CMakeFiles/test_autouic.dir/test_autouic_autogen/mocs_compilation.cpp.o [ 60%] Building CXX object CMakeFiles/test_autouic.dir/src/main.cpp.o In file included from /home/yu/codefield/window/src/main.cpp:1: /home/yu/codefield/window/include/test.h:2:10: fatal error: ui_test.h: No such file or directory 2 | #include \u0026#34;ui_test.h\u0026#34; | ^~~~~~~~~~~ compilation terminated. 结合上面的报错可以发现，CMake 可能只会扫描add_executable的 SOURCE 中的头文件和源文件，若发现有文件包含了\u0026quot;ui_\u0026lt;base_ui\u0026gt;.h\u0026quot;，则会在 target test_autouic 的构建流程中调用 uic 生成头文件。\ntest_autouic 无法发现需要编译的 .ui 文件，报错处已经是 g++ 编译器展开头文件的流程，自然无法调用 uic 生成所需的头文件了。\n拓展实践 🍎：将 .ui 与 .cpp / .h 分离 如果想实现如下的工程结构，还需要配置 CMAKE_AUTOUIC_SEARCH_PATHS 变量，该变量用于配置 CMake 从哪些目录中搜索需要被编译的 .ui 文件。\n. ├── CMakeLists.txt ├── include │ └── test.h ├── src │ ├── main.cpp │ └── test.cpp └── ui └── test.ui 需要在 CMakeLists.txt 中写：\nset(CMAKE_AUTOUIC_SEARCH_PATHS ${CMAKE_SOURCE_DIR}/ui) 否则 uic 会报错：\n[ 20%] Automatic MOC and UIC for target test_autouic AutoUic error ------------- \u0026#34;SRC:/include/test.h\u0026#34; includes the uic file \u0026#34;ui_test.h\u0026#34;, but the user interface file \u0026#34;test.ui\u0026#34; could not be found in the following directories \u0026#34;SRC:/include\u0026#34; ","permalink":"https://yusjade.github.io/posts/cmake_autouic_problem/","summary":"\u003ch2 id=\"解决办法\"\u003e解决办法\u003c/h2\u003e\n\u003cp\u003e在启用 CMAKE_AUTOUIC 的同时，将使用了\u003ccode\u003e#include \u0026quot;ui_\u0026lt;base_ui\u0026gt;.h\u0026quot;\u003c/code\u003e的头文件加入到\u003ccode\u003eadd_executable\u003c/code\u003e的 SOURCE 中即可。\u003c/p\u003e","title":"CMake + Qt 无法编译.ui文件的解决办法"},{"content":"在 Dify 中配置 Jina 在 设置 - 模型供应商 - 安装模型供应商 选择安装 Jina 模型供应商，为知识库提供 Embedding 模型和 Rerank 模型。\n在 设置 - 数据来源 - Web 站点 使用 Jina Reader 配置 Jina API key，key 可以通过访问 Jina 官网免费获得：jina.ai\n新建知识库 创建知识库时在数据源处选择“同步自 Web 站点”，工具选择 Jina Reader，将博客中带有所有文章列表的网页 url 粘贴进去，勾选“爬取子页面”，限制数量适当拉高，否则可能爬取不到所有文章。\n运行后会显示可选的页面，选择需要纳入知识库的文章即可。\n配置知识库 参考下列配置，我这里选择了高质量索引模式 + 混合检索的 Rerank 模型，分别使用了 Jina 的 jina-embeddings-v2-base-zh embedding 模型和 jina-reranker-v2-base-multilingual rerank 模型。\nembedding 模型也可以选择使用 ollama 自部署的 bge-m3 模型。\n知识库创建后会为文档产生索引，在应用中可选择添加知识库，这样大模型就能从知识库中获取额外的信息来生成回答。\n","permalink":"https://yusjade.github.io/posts/dify_use_knowledge_jina/","summary":"\u003ch2 id=\"在-dify-中配置-jina\"\u003e在 Dify 中配置 Jina\u003c/h2\u003e\n\u003cp\u003e在 \u003ccode\u003e设置 - 模型供应商 -  安装模型供应商\u003c/code\u003e 选择安装 Jina 模型供应商，为知识库提供 Embedding 模型和 Rerank 模型。\u003c/p\u003e\n\u003cp\u003e在 \u003ccode\u003e设置 - 数据来源 - Web 站点 使用 Jina Reader\u003c/code\u003e 配置 Jina API key，key 可以通过访问 Jina 官网免费获得：\u003ca href=\"https://jina.ai/reader/\"\u003ejina.ai\u003c/a\u003e\u003c/p\u003e","title":"Dify | 使用知识库与Jina获取博客内容"},{"content":" 参考 Issue: \u0026ldquo;Knowledge\u0026rdquo; is not working: \u0026ldquo;tool invoke error: \u0026lsquo;Document\u0026rsquo; object has no attribute \u0026lsquo;doc_metadat\u0026rsquo;\u0026quot;#14900\nDify 在调用知识库时，字段 doc_metadata 拼写错误成了 doc_metadat，官方已在上周修复了源码，但 docker 镜像迟迟未发布，需要自己更新镜像中的代码。\n# 使用 bash 终端进入容器 docker exec -it \u0026lt;your_container_name\u0026gt; /bin/bash 容器名一般是 docker-api-1，可以通过 docker ps 命令来查看\n修复文件第 175 行的代码错误：\nsed -i \u0026#39;175c\u0026#34;doc_metadata\u0026#34;: document.doc_metadata, # type:ignore\u0026#39; \\ core/tools/utils/dataset_retriever/dataset_retriever_tool.py exit # 退出 docker 容器 # 提交对镜像的修改 docker commit \u0026lt;your_container_name\u0026gt; langgenius/dify-api:1.0.1 编辑 docker-compose.yaml 文件，将所有 dify-api 版本替换为 1.0.1\n然后执行启动命令，docker 会重新创建容器：\ndocker compose up -d ","permalink":"https://yusjade.github.io/posts/fix_dify_doc_metadata/","summary":"\u003cblockquote\u003e\n\u003cp\u003e参考 Issue: \u003ca href=\"https://github.com/langgenius/dify/issues/14900\"\u003e\u0026ldquo;Knowledge\u0026rdquo; is not working: \u0026ldquo;tool invoke error: \u0026lsquo;Document\u0026rsquo; object has no attribute \u0026lsquo;doc_metadat\u0026rsquo;\u0026quot;#14900\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eDify 在调用知识库时，字段 \u003ccode\u003edoc_metadata\u003c/code\u003e 拼写错误成了 \u003ccode\u003edoc_metadat\u003c/code\u003e，官方已在上周修复了源码，但 docker 镜像迟迟未发布，需要自己更新镜像中的代码。\u003c/p\u003e","title":"Dify | 修复 “doc_metadata” 字段引发的问题"},{"content":" 目标：借助 Dify 使用 deepseek-chat 模型的 Function Calling 能力，使 agent 获得调用留言板信息 API 的能力。Function Calling 详见 | DeepSeek API Docs\n配置模型供应商 新建工具 Tool 导入 OpenAPI Schema OpenAPI 是用来定义 HTTP APIs 的一套“语言”，它可以描述一个 HTTP 服务暴露了什么“模样”的接口，这里使用我的留言板服务的 OpenAPI Schema，如此配置之后，模型就能理解应该以什么样的数据结构去请求我们 HTTP 服务，也能正确解析接口返回的响应数据。\nopenapi: 3.0.3 info: title: 留言板服务 version: 1.0.0 servers: - url: \u0026#34;http://{hostname}/api\u0026#34; variables: hostname: default: 127.0.0.1 paths: /message-board: get: description: 获取留言板上的所有留言 responses: \u0026#34;200\u0026#34;: description: todo content: application/json: schema: type: array items: $ref: \u0026#34;#/components/schemas/Message\u0026#34; default: description: todo content: application/json: schema: $ref: \u0026#34;#/components/schemas/Error\u0026#34; post: description: 发布一条留言 requestBody: required: true content: application/json: schema: $ref: \u0026#34;#/components/schemas/Message\u0026#34; responses: \u0026#34;200\u0026#34;: description: todo default: description: todo content: application/json: schema: $ref: \u0026#34;#/components/schemas/Error\u0026#34; components: schemas: Message: type: object properties: id: type: string content: type: string datetime: type: string Error: type: object properties: message: type: string 配置 Function Description description 是关系到模型调用工具的时机，详见文档对话补全 | DeepSeek API Docs：\n在 Agent 中添加工具进行对话测试 对话中使用“留言板情况如何？”、“今天留言板有没有什么值得注意的留言？”、“最近留言都在讲什么事情？”来测试\n","permalink":"https://yusjade.github.io/posts/dify_agent%E9%85%8D%E7%BD%AEfunction_calling/","summary":"\u003cblockquote\u003e\n\u003cp\u003e目标：借助 Dify 使用 deepseek-chat 模型的 \u003cstrong\u003eFunction Calling\u003c/strong\u003e 能力，使 agent 获得调用留言板信息 API 的能力。\u003ca href=\"https://api-docs.deepseek.com/zh-cn/guides/function_calling\"\u003eFunction Calling 详见 | DeepSeek API Docs\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"配置模型供应商\"\u003e配置模型供应商\u003c/h2\u003e\n\u003cimg src=\"/images/llm_provider.png\"\u003e\n\u003ch2 id=\"新建工具-tool\"\u003e新建工具 Tool\u003c/h2\u003e\n\u003ch3 id=\"导入-openapi-schema\"\u003e导入 OpenAPI Schema\u003c/h3\u003e\n\u003cp\u003eOpenAPI 是用来定义 HTTP APIs 的一套“语言”，它可以描述一个 HTTP 服务暴露了什么“模样”的接口，这里使用我的留言板服务的 OpenAPI Schema，如此配置之后，\u003cstrong\u003e模型就能理解应该以什么样的数据结构去请求我们 HTTP 服务\u003c/strong\u003e，也能正确解析接口返回的响应数据。\u003c/p\u003e","title":"Dify | Agent 配置 Function Calling"},{"content":"part1: 拉取 Yolov7 仓库并配置适用的虚拟环境 part1-1: 安装 Git 和 MiniConda Git 是一个分布式版本控制系统，主要用于跟踪代码变更、协作开发和版本管理。\n下载地址\u0026amp;官网： Git\nMiniConda 是 Anaconda 的轻量版，用于管理 Python 环境和包。\n下载地址\u0026amp;官网：Distribution/Free Download\npart1-2: 拉取仓库并配置 Python 虚拟环境 使用 git 拉取 Yolov7 的仓库。\ncd \u0026lt;你的代码工作目录\u0026gt; git clone https://github.com/WongKinYiu/yolov7.git cd yolov7 仓库内提供了 requirements.txt ，其列出了项目所依赖的所有第三方库及其版本信息。使用 conda 新建一个 Python 虚拟环境，切换至刚刚创建的环境，接着使用环境中的包管理工具 pip 来安装所需的第三方包。\nconda create --name yolov7 python=3.8 -y conda activate yolov7 pip install -r requirements.txt part2: 跑通项目前的一些准备 part2-0: 了解 Yolov7 仓库的项目结构 part2-0-1 目录结构 . ├── cfg // 模型配置文件 │ ├── baseline // 基础配置文件，定义了不同网络架构的 YAML 文件 │ │ ├── r50-csp.yaml │ │ ├── x50-csp.yaml │ │ ├── yolor-csp-x.yaml │ │ ├── yolor-csp.yaml │ │ ├── yolor-d6.yaml │ │ ├── yolor-e6.yaml │ │ ├── yolor-p6.yaml │ │ ├── yolor-w6.yaml │ │ ├── yolov3-spp.yaml │ │ ├── yolov3.yaml │ │ └── yolov4-csp.yaml │ ├── deploy // 部署配置文件，针对特定的 YOLOv7 变种进行配置 │ │ ├── yolov7-d6.yaml │ │ ├── yolov7-e6e.yaml │ │ ├── yolov7-e6.yaml │ │ ├── yolov7-tiny-silu.yaml │ │ ├── yolov7-tiny.yaml │ │ ├── yolov7-w6.yaml │ │ ├── yolov7x.yaml │ │ └── yolov7.yaml │ └── training // 训练时使用的配置文件 │ ├── yolov7-d6.yaml │ ├── yolov7-e6e.yaml │ ├── yolov7-e6.yaml │ ├── yolov7-tiny.yaml │ ├── yolov7-w6.yaml │ ├── yolov7x.yaml │ └── yolov7.yaml ├── data // 包含了训练和推理时使用的数据配置文件 │ ├── coco.yaml │ ├── hyp.scratch.custom.yaml │ ├── hyp.scratch.p5.yaml │ ├── hyp.scratch.p6.yaml │ └── hyp.scratch.tiny.yaml ├── deploy // 将 YOLOv7 部署为 TensorRT 引擎到 Triton 推理服务器 ├── detect.py // 检测脚本 ├── export.py // 模型导出脚本 ├── figure // 存放着一些预测结果 ├── hubconf.py ├── inference // 推理时使用到的一些资源 ├── LICENSE.md ├── models // 包含 YOLOv7 模型的实现代码 │ ├── common.py │ ├── experimental.py │ └── yolo.py ├── paper // 论文 │ └── yolov7.pdf ├── README.md ├── requirements.txt // 记录项目运行所依赖的第三方包 ├── runs // 存放每次 train/detect 的记录，如训练后的权重、检测结果图、损失图等 │ └── detect │ ├── exp │ └── exp2 ├── scripts // 辅助脚本 │ └── get_coco.sh ├── test.py ├── tools // 包含了一些用于模型比较、可视化、转换等操作的工具脚本 ├── traced_model.pt // 追踪模型 ├── train_aux.py // train_aux.py 包含一些辅助功能或代码 ├── train.py // train.py 是主要的训练脚本 ├── utils // 存放一些工具函数 ├── yolov7.pt └─── yolov7-tiny.pt part2-0-2 性能对比 part3: 把项目跑起来 part3-1: 推理 part3-2: 训练 python train.py --weights yolov7-tiny.pt --data data/\u0026lt;你的数据集配置.yaml\u0026gt; --hyp data/hyp_scratch.tiny.yaml hyp 是 hyperparameters（超参数）的缩写，表示模型训练过程中使用的各种超参数配置。\ntrain.py 会启动 TensorBoard，训练进行时可以用浏览器打开 TensorBoard 查看当前的训练情况。\n“ TensorBoard 是一个强大的可视化工具，它可以帮助开发者在训练模型时更好地理解和调试模型。它通过提供损失、准确率、图像示例等多种类型的日志信息，使得模型训练过程的分析和改进变得更加直观和方便。TensorBoard 不仅可以用于 TensorFlow，也可以与 PyTorch 等其他框架结合使用。”\n训练完成后，可以在 runs/train 中找到对应的 exp\u0026lt;n\u0026gt; 文件夹，里面存放着本次训练产生的各种文件。\n. ├── confusion_matrix.png // 混淆矩阵，用于可视化模型在不同类别上的分类性，显示了模型预测的类别与实际类别之间的关系 ├── events.out.tfevents.1706176268.featurize.23402.0 // TensorBoard 日志文件，用于可视化训练过程中的损失、指标等,可以使用TensorBoard加载该文件进行更详细的分析 ├── F1_curve.png // F1分数曲线，F1是精确率（Precision）和召回率（Recall）的调和平均值 ├── hyp.yaml // 超参数配置文件 ├── opt.yaml // 训练选项配置文件 ├── P_curve.png // 精确率（Precision）曲线，展示了模型在不同置信度阈值下的精确率变化 ├── PR_curve.png // 精确率-召回率曲线（Precision-Recall Curve），用于评估模型在不同阈值下的精确率和召回率的平衡 ├── R_curve.png // 召回率（Recall）曲线，展示了模型在不同置信度阈值下的召回率变化 ├── results.png // 训练结果的汇总图 ├── results.txt // 训练结果的文本文件，记录了每一轮训练的具体指标 ├── test_batch0_labels.jpg // 测试集的真实标签可视化图像 ├── test_batch0_pred.jpg // 测试集的预测结果可视化图像 ├── ... ├── test_batch2_labels.jpg ├── test_batch2_pred.jpg ├── train_batch0.jpg // 训练集的批次可视化图像 ├── ... ├── train_batch9.jpg └── weights ├── best_218.pt ├── ... // 训练过程中不同阶段表现最好的模型权重文件 ├── best_458.pt ├── best.pt // 训练过程中表现最好的模型权重文件 ├── epoch_000.pt ├── ... // 每一轮训练生成的模型权重文件 ├── epoch_999.pt ├── init.pt // 初始化模型权重文件，通常是训练开始前的初始权重 └── last.pt // 最后一轮训练生成的模型权重文件 part4: 部署到 Android —— 使用 ncnn ncnn 是腾讯发布的一个开源的、专为移动设备优化的神经网络推理框架：\nTencent/ncnn ncnn is a high-performance neural network inference framework optimized for the mobile platform part4-0: 使用 export.py 导出非 end2end 的 onnx 模型 需要一个非 end2end 的模型，即去掉模型的 Detect 层，Detect 层的功能在推理程序的后处理部分完成。\npython export.py --weights yolov7-tiny.pt --img-size 640 640 part4-1: 使用 pnnx 转化为 ncnn ncnn 提供了转化工具 pnnx，可以通过 pip 安装：\npip install pnnx 使用教程可见官方文档：Tencent/ncnn: use ncnn with pytorch or onnx\n这里以 yolov7-tiny.pt 为例，使用 pnnx 转化的指令为：\npnnx yolov7-tiny.onnx part4-2: 使用 cpp + NDK 编写推理程序 这部分基于一个 ncnn + yolov7 的 Android 例程：\nxiang-wuu/ncnn-android-yolov7 Android Live Demo inferenece of Yolov7 using ncnn 下面是提取推理结果的代码片段，其实就是实现了 Detect 检测层的功能：\n// app/src/main/jni/yolo.cpp static void generate_proposals(const ncnn::Mat \u0026amp;anchors, int stride, const ncnn::Mat \u0026amp;in_pad, const ncnn::Mat \u0026amp;feat_blob, float prob_threshold, std::vector\u0026lt;Object\u0026gt; \u0026amp;objects) { const int num_grid_x = feat_blob.w; const int num_grid_y = feat_blob.h; const int num_anchors = anchors.w / 2; const int num_class = feat_blob.c / num_anchors - 5; const int feat_offset = num_class + 5; // 遍历各个锚框，一般每个尺寸的特征图对应三个锚框 for (int q = 0; q \u0026lt; num_anchors; q++) { const float anchor_w = anchors[q * 2]; const float anchor_h = anchors[q * 2 + 1]; // 解析特征图得到推理结果，这部分代码可以参考 yolov7 的 Detect 层代码实现 for (int i = 0; i \u0026lt; num_grid_y; i++) { for (int j = 0; j \u0026lt; num_grid_x; j++) { // 寻找 score 最大的 class，这部分不属于 Detect 层 int class_index = 0; float class_score = -FLT_MAX; for (int k = 0; k \u0026lt; num_class; k++) { float score = feat_blob.channel(q * feat_offset + 5 + k).row(i)[j]; if (score \u0026gt; class_score) { class_index = k; class_score = score; } } float box_score = feat_blob.channel(q * feat_offset + 4).row(i)[j]; float confidence = sigmoid(box_score) * sigmoid(class_score); if (confidence \u0026gt;= prob_threshold) { // 参考 yolov7/models/yolo.py Detect forward // y = x[i].sigmoid() // y[..., 0:2] = (y[..., 0:2] * 2. - 0.5 + self.grid[i].to(x[i].device)) * self.stride[i] # xy // y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i] # wh float dx = sigmoid(feat_blob.channel(q * feat_offset + 0).row(i)[j]); float dy = sigmoid(feat_blob.channel(q * feat_offset + 1).row(i)[j]); float dw = sigmoid(feat_blob.channel(q * feat_offset + 2).row(i)[j]); float dh = sigmoid(feat_blob.channel(q * feat_offset + 3).row(i)[j]); float pb_cx = (dx * 2.f - 0.5f + j) * stride; float pb_cy = (dy * 2.f - 0.5f + i) * stride; float pb_w = pow(dw * 2.f, 2) * anchor_w; float pb_h = pow(dh * 2.f, 2) * anchor_h; float x0 = pb_cx - pb_w * 0.5f; float y0 = pb_cy - pb_h * 0.5f; float x1 = pb_cx + pb_w * 0.5f; float y1 = pb_cy + pb_h * 0.5f; Object obj; obj.rect.x = x0; obj.rect.y = y0; obj.rect.width = x1 - x0; obj.rect.height = y1 - y0; obj.label = class_index; obj.prob = confidence; objects.push_back(obj); } } } } } 从模型中提取三种尺寸的特征图输出，经过后处理后得到推理结果：\nint Yolo::detect(const cv::Mat \u0026amp;rgb, std::vector\u0026lt;Object\u0026gt; \u0026amp;objects, float prob_threshold, float nms_threshold) { int img_w = rgb.cols; int img_h = rgb.rows; // letterbox pad to multiple of 32 int w = img_w; int h = img_h; float scale = 1.f; if (w \u0026gt; h) { scale = (float) target_size / w; w = target_size; h = h * scale; } else { scale = (float) target_size / h; h = target_size; w = w * scale; } const int max_stride = 64; ncnn::Mat in = ncnn::Mat::from_pixels_resize(rgb.data, ncnn::Mat::PIXEL_RGB, img_w, img_h, w, h); // pad to target_size rectangle int wpad = (w + max_stride - 1) / max_stride * max_stride - w; int hpad = (h + max_stride - 1) / max_stride * max_stride - h; ncnn::Mat in_pad; ncnn::copy_make_border(in, in_pad, hpad / 2, hpad - hpad / 2, wpad / 2, wpad - wpad / 2, ncnn::BORDER_CONSTANT, 114.f); in_pad.substract_mean_normalize(0, norm_vals); ncnn::Extractor ex = yolo.create_extractor(); ex.input(\u0026#34;in0\u0026#34;, in_pad); std::vector\u0026lt;Object\u0026gt; proposals; // stride 8 { ncnn::Mat out; ex.extract(\u0026#34;out0\u0026#34;, out); ncnn::Mat anchors(6); anchors[0] = 12.f; anchors[1] = 16.f; anchors[2] = 19.f; anchors[3] = 36.f; anchors[4] = 40.f; anchors[5] = 28.f; std::vector\u0026lt;Object\u0026gt; objects8; generate_proposals(anchors, 8, in_pad, out, prob_threshold, objects8); proposals.insert(proposals.end(), objects8.begin(), objects8.end()); } // stride 16 { ncnn::Mat out; ex.extract(\u0026#34;out1\u0026#34;, out); ncnn::Mat anchors(6); anchors[0] = 36.f; anchors[1] = 75.f; anchors[2] = 76.f; anchors[3] = 55.f; anchors[4] = 72.f; anchors[5] = 146.f; std::vector\u0026lt;Object\u0026gt; objects16; generate_proposals(anchors, 16, in_pad, out, prob_threshold, objects16); proposals.insert(proposals.end(), objects16.begin(), objects16.end()); } // stride 32 { ncnn::Mat out; ex.extract(\u0026#34;out2\u0026#34;, out); ncnn::Mat anchors(6); anchors[0] = 142.f; anchors[1] = 110.f; anchors[2] = 192.f; anchors[3] = 243.f; anchors[4] = 459.f; anchors[5] = 401.f; std::vector\u0026lt;Object\u0026gt; objects32; generate_proposals(anchors, 32, in_pad, out, prob_threshold, objects32); proposals.insert(proposals.end(), objects32.begin(), objects32.end()); } // sort all proposals by score from highest to lowest qsort_descent_inplace(proposals); // apply nms with nms_threshold std::vector\u0026lt;int\u0026gt; picked; nms_sorted_bboxes(proposals, picked, nms_threshold); int count = picked.size(); objects.resize(count); for (int i = 0; i \u0026lt; count; i++) { objects[i] = proposals[picked[i]]; // adjust offset to original unpadded float x0 = (objects[i].rect.x - (wpad / 2)) / scale; float y0 = (objects[i].rect.y - (hpad / 2)) / scale; float x1 = (objects[i].rect.x + objects[i].rect.width - (wpad / 2)) / scale; float y1 = (objects[i].rect.y + objects[i].rect.height - (hpad / 2)) / scale; // clip x0 = std::max(std::min(x0, (float) (img_w - 1)), 0.f); y0 = std::max(std::min(y0, (float) (img_h - 1)), 0.f); x1 = std::max(std::min(x1, (float) (img_w - 1)), 0.f); y1 = std::max(std::min(y1, (float) (img_h - 1)), 0.f); objects[i].rect.x = x0; objects[i].rect.y = y0; objects[i].rect.width = x1 - x0; objects[i].rect.height = y1 - y0; } return 0; } part4-2-1: 匹配模型输出端 extract 的第一个入参要注意与实际模型的输出端名称匹配。\nex.extract(\u0026#34;out0\u0026#34;, out); 可以以文本方式打开使用 pnnx 转换后得到的 yolov7_tiny.pnnx.param，查看输出端的名称。\n# Op # Name # Attr pnnx.Output out0 1 0 135 #135=(1,3,80,80,85)f32 pnnx.Output out1 1 0 138 #138=(1,3,40,40,85)f32 pnnx.Output out2 1 0 141 #141=(1,3,20,20,85)f32 part4-3: 加载 .param 和 .bin ncnn 模型文件分为网络结构文件.param和权重参数.bin，放到工程目录下的 app/src/main /assets 中，加载代码部分在 app/src/main/jni/yolo.cpp 的 Yolo::load 函数。\n","permalink":"https://yusjade.github.io/posts/note-yolov7-employ-ncnn/","summary":"\u003ch2 id=\"part1-拉取-yolov7-仓库并配置适用的虚拟环境\"\u003epart1: 拉取 Yolov7 仓库并配置适用的虚拟环境\u003c/h2\u003e\n\u003ch3 id=\"part1-1-安装-git-和-miniconda\"\u003epart1-1: 安装 Git 和 MiniConda\u003c/h3\u003e\n\n\u003cdiv class=\"notice notice-info\" \u003e\n    \u003cdiv class=\"notice-title\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon notice-icon\" viewBox=\"0 0 512 512\"\u003e\u003cpath d=\"M256 8a248 248 0 100 496 248 248 0 000-496zm0 110a42 42 0 110 84 42 42 0 010-84zm56 254c0 7-5 12-12 12h-88c-7 0-12-5-12-12v-24c0-7 5-12 12-12h12v-64h-12c-7 0-12-5-12-12v-24c0-7 5-12 12-12h64c7 0 12 5 12 12v100h12c7 0 12 5 12 12v24z\"/\u003e\u003c/svg\u003e\u003c/div\u003e\u003cp\u003eGit 是一个分布式版本控制系统，主要用于跟踪代码变更、协作开发和版本管理。\u003c/p\u003e","title":"使用 ncnn 将 Yolov7 部署到 Android"},{"content":" SerenNan SerenNan的博客 ","permalink":"https://yusjade.github.io/friends/","summary":"\u003ca target=\"_blank\" href=https://serennan.github.io/ title=SerenNan class=\"friendurl\"\u003e\n  \u003cdiv class=\"frienddiv\"\u003e\n    \u003cdiv class=\"frienddivleft\"\u003e\n      \u003cimg class=\"myfriend\" src=https://serennan.github.io/img/avatar_hu_47dcc2efc37d0778.png /\u003e\n    \u003c/div\u003e\n    \u003cdiv class=\"frienddivright\"\u003e\n      \u003cdiv class=\"friendname\"\u003eSerenNan\u003c/div\u003e\n      \u003cdiv class=\"friendinfo\"\u003eSerenNan的博客\u003c/div\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n\u003c/a\u003e","title":"友链"}]